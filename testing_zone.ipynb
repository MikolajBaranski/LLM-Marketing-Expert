{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.base_prompts import (\n",
    "    PROMPT_A1,\n",
    "    PROMPT_A2,\n",
    "    PROMPT_B,\n",
    "    PROMPT_C\n",
    ")\n",
    "from utils.config import (\n",
    "    IMAGE_RAW_PATH,\n",
    "    IMAGE_HEATMAP_PATH,\n",
    "    MODEL_ID\n",
    ")\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import json\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketingAgent:\n",
    "    \"\"\"\n",
    "    Main class that contains the four different prompt pipelines\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            image_raw_path: str = IMAGE_RAW_PATH,\n",
    "            image_heatmap_path: str = IMAGE_HEATMAP_PATH,\n",
    "            model_id: str = MODEL_ID\n",
    "        ):\n",
    "        self.image_raw = Image.open(image_raw_path)\n",
    "        self.image_heat = Image.open(image_heatmap_path)\n",
    "        self.pipe = pipeline(\"image-to-text\", model=model_id)\n",
    "    \n",
    "    def format_prompt(self, prompt):\n",
    "        complete_prompt = fr'USER: <image>\\n {prompt} \\nASSISTANT:\\n'\n",
    "        return complete_prompt\n",
    "    \n",
    "    def clean_output(self, prompt_output):\n",
    "        return json.loads(prompt_output[0][\"generated_text\"].split(\"ASSISTANT:\\\\n\\n\\n\", 1)[-1].replace(r'\\_', '_'))\n",
    "    \n",
    "    def combine_outputs(\n",
    "            self,\n",
    "            json_output_A1,\n",
    "            json_output_A2,\n",
    "            json_output_B\n",
    "        ):\n",
    "        # Extract elements from each JSON output\n",
    "        ad_description = json_output_A1[0][\"ad_description\"]\n",
    "        ad_purpose = json_output_A1[0][\"ad_purpose\"]\n",
    "        ad_saliency_description = json_output_A2[0][\"saliency_description\"]\n",
    "        ad_cognitive_description = json_output_B[0][\"cognitive_description\"]\n",
    "\n",
    "        # Combine into a new JSON object\n",
    "        json_combined = {\n",
    "            \"ad_description\": ad_description,\n",
    "            \"ad_purpose\": ad_purpose,\n",
    "            \"ad_saliency_description\": ad_saliency_description,\n",
    "            \"ad_cognitive_description\": ad_cognitive_description\n",
    "        }\n",
    "        return json_combined\n",
    "\n",
    "    def run_marketing_prompt(self, image, prompt, json_combined={}, multimodal=True):\n",
    "        if multimodal:\n",
    "            prompt = self.format_prompt(prompt)\n",
    "            prompt_output = self.pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "        else:\n",
    "            prompt = f'{prompt} {json_combined}'\n",
    "            prompt = self.format_prompt(prompt)\n",
    "            prompt_output = self.pipe(prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "        json_output = self.clean_output(prompt_output)\n",
    "        return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(self, prompt):\n",
    "    complete_prompt = fr'USER: <image>\\n {prompt} \\nASSISTANT:'\n",
    "    return complete_prompt\n",
    "\n",
    "def clean_output(prompt_output):\n",
    "    return json.loads(prompt_output[0][\"generated_text\"].split(\"ASSISTANT:\\\\n\\n\\n\", 1)[-1].replace(r'\\_', '_'))\n",
    "\n",
    "def combine_outputs(\n",
    "        json_output_A1,\n",
    "        json_output_A2,\n",
    "        json_output_B\n",
    "    ):\n",
    "    # Extract elements from each JSON output\n",
    "    ad_description = json_output_A1[0][\"ad_description\"]\n",
    "    ad_purpose = json_output_A1[0][\"ad_purpose\"]\n",
    "    ad_saliency_description = json_output_A2[0][\"saliency_description\"]\n",
    "    ad_cognitive_description = json_output_B[0][\"cognitive_description\"]\n",
    "\n",
    "    # Combine into a new JSON object\n",
    "    json_combined = {\n",
    "        \"ad_description\": ad_description,\n",
    "        \"ad_purpose\": ad_purpose,\n",
    "        \"ad_saliency_description\": ad_saliency_description,\n",
    "        \"ad_cognitive_description\": ad_cognitive_description\n",
    "    }\n",
    "    return json_combined\n",
    "\n",
    "def run_marketing_prompt(self, image, prompt, json_combined={}, multimodal=True):\n",
    "    if multimodal:\n",
    "        prompt = self.format_prompt(prompt)\n",
    "        prompt_output = self.pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "    else:\n",
    "        prompt = f'{prompt} {json_combined}'\n",
    "        prompt = self.format_prompt(prompt)\n",
    "        prompt_output = self.pipe(prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "    json_output = self.clean_output(prompt_output)\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = predict_helper.format_prompt(PROMPT_A1)\n",
    "prompt_output = predict_helper.pipe(predict_helper.image_raw, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'USER:  \\\\n \\n<role>\\nYou are a Senior Insights Manager with decades of experience, and a background\\nin marketing.\\n</role>\\n<input-overview>\\nYou are provided with an image of a digital advertisement.\\n</input-overview>\\n<task>\\nYou have two tasks:\\n1) Provide a detailed description of the advert. In other words, identify and\\ndescribe the key elements such as the product being advertised, the brand name,\\nand the call-to-action (CTA), where available.\\n2) Additionally, assess and determine the primary purpose of the advertisement,\\ni.e. whether it is aimed at brand building or aimed at driving conversion.\\n</task>\\n<response-template>\\nProvide the output in the following JSON format\\n```\\n[\\n    {\\n        \"ad_description\":$description,\\n        \"ad_purpose\":$purpose\\n    }\\n]\\n```\\n\\nIn this format, $description is a placeholder for the description of the\\nadvert, $purpose can only be either \"brand-building\" or \"conversion\".\\n</response-template>.\\n \\\\nASSISTANT:\\\\n\\n\\n[\\n{\\n\"ad\\\\_description\": \"A woman wearing a colorful jacket and a knitted hat is posing for a photo. She is wearing a pink hat and a pink jacket. The background is a brightly colored gradient. The advertisement is for Snowstyle, a clothing brand. The call-to-action is to visit the Snowstyle website.\",\\n\"ad\\\\_purpose\": \"conversion\"\\n}\\n]'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ad_description': 'A woman wearing a colorful jacket and a knitted hat is posing for a photo. She is wearing a pink hat and a pink jacket. The background is a brightly colored gradient. The advertisement is for Snowstyle, a clothing brand. The call-to-action is to visit the Snowstyle website.',\n",
       "  'ad_purpose': 'conversion'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(prompt_output[0][\"generated_text\"].split(\"ASSISTANT:\\\\n\\n\\n\", 1)[-1].replace(r'\\_', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "predict_helper = MarketingAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = predict_helper.run_marketing_prompt(predict_helper.image_raw,PROMPT_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
